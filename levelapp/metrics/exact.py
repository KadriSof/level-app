"""levelapp/metrics/exact.py"""
import datetime

from typing import Dict, Any, Callable, Optional

from rapidfuzz import distance

from levelapp.core.base import BaseMetric
from levelapp.utils.monitoring import FunctionMonitor


class ExactMatch(BaseMetric):
    """Binary exact match comparison (1.0 for exact match, 0.0 otherwise)"""

    def __init__(self, processor: Callable = None, score_cutoff: float = 1.0):
        self.processor = processor
        self.score_cutoff = score_cutoff

    def _get_params(self) -> Dict[str, Any]:
        return {
            'processor': repr(self.processor) if self.processor else None,
            'score_cutoff': self.score_cutoff
        }

    @FunctionMonitor.monitor(name="exact_match", cached=True, enable_timing=True)
    def compute(self, generated: str, reference: str) -> Dict[str, Any]:
        """"
        Compute the exact match score between generated and reference strings.

        Args:
            generated (str): The text generated by the agent.
            reference (str): The expected reference text.

        Returns:
            Dict[str, Any]: A dictionary containing the exact match score and metadata.
        """
        if not isinstance(generated, str) or not isinstance(reference, str):
            raise TypeError("Inputs must be strings")

        score = distance.Levenshtein.normalized_similarity(
            s1=generated,
            s2=reference,
            processor=self.processor,
            score_cutoff=self.score_cutoff
        )

        return {
            "score": score,
            "metadata": {
                "type": self.__class__.__name__,
                "params": self._get_params(),
                "inputs": {
                    "generated_length": len(generated),
                    "reference_length": len(reference)
                },
                "timestamp": datetime.datetime.now()
            }
        }


class Levenshtein(BaseMetric):
    """Levenshtein edit distance (number of insertions, deletions, substitutions)"""

    def __init__(self, processor: Callable = None, score_cutoff: float | None = None):
        self.processor = processor
        self.score_cutoff = score_cutoff

    def _get_params(self) -> Dict[str, Any]:
        return {
            'processor': repr(self.processor) if self.processor else None,
            'score_cutoff': self.score_cutoff
        }

    @FunctionMonitor.monitor(name="levenshtein", cached=True, enable_timing=True)
    def compute(self, generated: str, reference: str) -> Dict[str, Any]:
        """
        Compute the Levenshtein distance score between generated and reference strings.

        Args:
            generated (str): The text generated by the agent.
            reference (str): The expected reference text.

        Returns:
            Dict[str, Any]: A dictionary containing the Levenshtein score and metadata.
        """
        if not isinstance(generated, str) or not isinstance(reference, str):
            raise TypeError("Inputs must be strings")

        score = distance.Levenshtein.normalized_similarity(
            s1=generated,
            s2=reference,
            processor=self.processor,
            score_cutoff=self.score_cutoff
        )

        return {
            "score": score,
            "metadata": {
                "type": self.__class__.__name__,
                "params": self._get_params(),
                "inputs": {
                    "generated_length": len(generated),
                    "reference_length": len(reference)
                },
                "timestamp": datetime.datetime.now()
            }
        }


class JaroWinkler(BaseMetric):
    """Jaro-Winkler distance (similarity measure for strings)"""

    def __init__(self, processor: Callable = None, score_cutoff: float | None = None):
        self.processor = processor
        self.score_cutoff = score_cutoff

    def _get_params(self) -> Dict[str, Any]:
        return {
            'processor': repr(self.processor) if self.processor else None,
            'score_cutoff': self.score_cutoff
        }

    @FunctionMonitor.monitor(name="jaro_winkler", cached=True, enable_timing=True)
    def compute(self, generated: str, reference: str) -> Dict[str, Any]:
        """
        Compute the Jaro-Winkler distance score between generated and reference strings.

        Args:
            generated (str): The text generated by the agent.
            reference (str): The expected reference text.

        Returns:
            Dict[str, Any]: A dictionary containing the Jaro-Winkler score and metadata.
        """
        if not isinstance(generated, str) or not isinstance(reference, str):
            raise TypeError("Inputs must be strings")

        score = distance.JaroWinkler.normalized_similarity(
            s1=generated,
            s2=reference,
            processor=self.processor,
            score_cutoff=self.score_cutoff
        )

        return {
            "score": score,
            "metadata": {
                "type": self.__class__.__name__,
                "params": self._get_params(),
                "inputs": {
                    "generated_length": len(generated),
                    "reference_length": len(reference)
                },
                "timestamp": datetime.datetime.now()
            }
        }


class Hamming(BaseMetric):
    """Hamming distance (character substitutions only, for equal-length strings)"""

    def __init__(self, processor: Callable = None, score_cutoff: float | None = None):
        self.processor = processor
        self.score_cutoff = score_cutoff

    def _get_params(self) -> Dict[str, Any]:
        return {
            'processor': repr(self.processor) if self.processor else None,
            'score_cutoff': self.score_cutoff
        }

    @FunctionMonitor.monitor(name="hamming", cached=True)
    def compute(self, generated: str, reference: str) -> Dict[str, Any]:
        """
        Compute the Hamming distance score between generated and reference strings.

        Args:
            generated (str): The text generated by the agent.
            reference (str): The expected reference text.

        Returns:
            Dict[str, Any]: A dictionary containing the Hamming score and metadata.
        """
        if not isinstance(generated, str) or not isinstance(reference, str):
            raise TypeError("Inputs must be strings")

        score = distance.Hamming.normalized_similarity(
            s1=generated,
            s2=reference,
            processor=self.processor,
            score_cutoff=self.score_cutoff
        )

        return {
            "score": score,
            "metadata": {
                "type": self.__class__.__name__,
                "params": self._get_params(),
                "inputs": {
                    "generated_length": len(generated),
                    "reference_length": len(reference)
                },
                "timestamp": datetime.datetime.now()
            }
        }


class PrefixMatch(BaseMetric):
    """Prefix similarity (1.0 if generated starts with reference)"""

    def __init__(self, processor: Callable = None, score_cutoff: float | None = None):
        self.processor = processor
        self.score_cutoff = score_cutoff

    def _get_params(self) -> Dict[str, Any]:
        return {
            'processor': repr(self.processor) if self.processor else None,
            'score_cutoff': self.score_cutoff
        }


    @FunctionMonitor.monitor(name="prefix_match", cached=True)
    def compute(self, generated: str, reference: str) -> Dict[str, Any]:
        if not reference:  # Empty prefix matches everything
            return {"score": 1.0, "metadata": {...}}

        score = distance.Prefix.normalized_similarity(
            s1=generated,
            s2=reference,
            processor=self.processor,
            score_cutoff=self.score_cutoff
        )

        return {
            "score": score,
            "metadata": {
                "type": self.__class__.__name__,
                "params": self._get_params(),
                "inputs": {
                    "prefix_length": len(reference),
                    "generated_length": len(generated)
                },
                "timestamp": datetime.datetime.now()
            }
        }


# Registry of all exact metrics
EXACT_METRICS = {
    "exact_match": ExactMatch,
    "levenshtein": Levenshtein,
    "jaro_winkler": JaroWinkler,
    "hamming": Hamming,
    "prefix_match": PrefixMatch
}